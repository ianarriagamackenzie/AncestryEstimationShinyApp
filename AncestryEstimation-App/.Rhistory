ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_continuous(breaks = NULL)
chrplot
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_continuous(breaks = c(1,2,3,4,5,6))
chrplot
?scale_x_continuous
?scale_x_reverse
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22))
chrplot
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22), expand = c(0,0))
chrplot
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22), expand = c(0,0)) +
theme(
panel.grid.major.x = element_blank()
)
chrplot
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22), expand = c(0,0)) +
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank()
)
chrplot
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22), expand = c(0,0)) +
theme(
panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank()
)
chrplot
runApp('GitHub/mixturesresearch/AncestryEstimation-App')
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22), expand = c(0,0)) +
theme(
panel.grid.major.y = element_blank()
#panel.grid.minor.y = element_blank()
)
chrplot
chrplot = ggplot(chrmelt, aes(Chromosome, Proportions, fill=Proportions)) +
facet_wrap( ~ Anc ,nrow = 1) +
geom_bar(stat="identity") +
ylim(c(0,1)) +
coord_flip() +
scale_fill_distiller(palette = 'Spectral')+
guides(fill = FALSE) +
scale_x_reverse(breaks = c(1:22), expand = c(0,0)) +
theme(
#panel.grid.major.y = element_blank()
panel.grid.minor.y = element_blank()
)
chrplot
runApp('GitHub/mixturesresearch/AncestryEstimation-App')
x = 100
y = 50
x + y
x = c(50,30,405,505)
shiny::runApp('GitHub/mixturesresearch/AncestryEstimation-App')
View(genome_tests_afr)
.7*.7*.7 + (.7*.7*.3)^3
.7*.7*.7 + (.7*.7*.3)3
.7*.7*.7 + (.7*.7*.3) * 3
(.95 * .6)/(.95*.6 + .92 +.4)
(.95 * .6)/(.95*.6 + .92*.4)
?comb
?combn
x = c(0,0,0,1,1,1)
combn(x)
combn(x, 6)
combn(x, 1)
combn(x, 3)
combn(x, 6)
?permutation
?permute
??permute
?combinations
library(gtools)
permutations(x, 6)
combinations(6,6,c(1,1,1,0,0,0))
combinations(6,6,x)
combinations(3,2,c('a','b','c'))
combinations(6,6,c(0,0,0,1,1,1))
permutations(6,6,c(0,0,0,1,1,1))
combinations(6,6,c('0','0','0','1','1','1'))
library(gtools)
combinations(6,6,c('0','0','0','1','1','1'))
t(combn(6,3,function(x)replace(numeric(6),x,1)))
t(combn(5,2,function(x)replace(numeric(6),x,1)))
t(combn(5,2,function(x)replace(numeric(5),x,1)))
t(combn(5,2,function(x)replace(numeric(5),x,1)))
t(combn(6,3,function(x)replace(numeric(6),x,1)))
t(combn(4,3,function(x)replace(numeric(4),x,1)))
t(combn(5,3,function(x)replace(numeric(5),x,1)))
t(combn(6,3,function(x)replace(numeric(6),x,1)))
shiny::runApp('GitHub/mixturesresearch/AncestryEstimation-App')
runApp('GitHub/mixturesresearch/AncestryEstimation-App')
runApp('GitHub/mixturesresearch/AncestryEstimation-App')
library(spatstat)
install.packages('spatstat')
jpine = data(japanesepines, package = spatstat)
library(spatstat)
jpine = data(japanesepines, package = spatstat)
data(japanesepines, package = spatstat)
jp = data(japanesepines, package = 'spatstat')
data(japanesepines, package = 'spatstat')
data(japanesepines, package = 'spatstat.data')
jp = data(japanesepines, package = 'spatstat.data')
summary(japanesepines)
summary(jp)
library(spatstat)
data(japanesepines, package = 'spatstat.data')
jp = japanesepines
plot(jp)
library(spatstat) # for inference on spatial point processes
library(smacpod)
install.packages('smacpod')
library(smacpod)
data(grave, package = "smacpod") # import data in ppp format
# determine affected and unaffected sides
af = which(grave$marks == "affected")
un = which(grave$marks == "unaffected")
# plot of event locations
plot(grave)
# recommended bandwidths for affected and unaffected graves
# in u- and v-directions
dim = 2
# Scott's bandwidths in u- and v-directions
# for each group
buaf = sd(grave$x[af])*length(af)^(-1/(dim+4))
bvaf = sd(grave$y[af])*length(af)^(-1/(dim+4))
buun = sd(grave$x[un])*length(un)^(-1/(dim+4))
bvun = sd(grave$y[un])*length(un)^(-1/(dim+4))
# intensity estimated for affected and unaffected groups
# using associated bandwidths from Scott's rule
iaf = spdensity(grave[af,], sigma = c(buaf, bvaf))
iun = spdensity(grave[un,], sigma = c(buun, bvun))
# plot perspective and contour plots of estimated intensity for affected sites
par(mfrow = c(1, 2))
persp(iaf, theta = 45, phi = 35, xlab = "u", ylab = "v", zlab = "density", main = "Estimated intensity function")
contour(iaf, xlab = "u", ylab = "v", main = "Affected grave locations")
points(grave, pch = ".")
# plot perspective and contour plots of estimated intensity for unaffected sites
par(mfrow = c(1, 2))
persp(iun, theta = 45, phi = 35, xlab = "u", ylab = "v", zlab = "density", main = "Estimated intensity function")
contour(iun, xlab = "u", ylab = "v", main = "Unaffected grave locations")
points(grave, pch = ".")
# plot perspective and contour plots of estimated intensity for unaffected sites
par(mfrow = c(1, 2))
contour(iaf, xlab = "u", ylab = "v", main = "Affected")
points(grave, pch = ".")
contour(iun, xlab = "u", ylab = "v", main = "Unaffected")
points(grave, pch = ".")
library(spatstat)
data(japanesepines, package = 'spatstat.data')
jp = japanesepines
plot(jp)
plot(density(jp, sigma = bw.scott(jp)))
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
jpenv = envelope(jp, Lest, nsim = 50, correction = 'Ripley', savefuns = TRUE)
res = qdir_envelope(env)
jpenv = envelope(jp, Lest, nsim = 50, correction = 'Ripley', savefuns = TRUE)
plot(jpenv, . - r ~ r)
jpenv = envelope(jp, Lest, nsim = 50, correction = 'Ripley', savefuns = TRUE)
plot(jpenv, . - r ~ r)
?envelope
jpenv = envelope(jp, Lest, nsim = 50, correction = 'Ripley', savefuns = TRUE)
plot(jpenv, . - r ~ r)
jpenv = envelope(jp, Lest, nsim = 50, correction = 'Ripley', savefuns = TRUE)
plot(jpenv, . - r ~ r)
jpenv = envelope(jp, Lest, nsim = 500, correction = 'Ripley', savefuns = TRUE)
plot(jpenv, . - r ~ r)
jpenv = envelope(jp, Lest, nsim = 500, correction = 'Ripley', savefuns = TRUE)
plot(jpenv, . - r ~ r)
plot(lohboot(jp, fun =  'Lest'), . - r ~ r)
plot(lohboot(jp, fun =  'Lest', nsim = 500, confidence = 0.95), . - r ~ r)
jpenv = envelope(jp, Lest, nsim = 500, correction = 'Ripley')
plot(jpenv, . - r ~ r)
plot(envelope(jp, Lest, nsim = 500, correction = 'Ripley'), . - r ~ r)
plot(envelope(jp, Lest, nsim = 500, correction = 'Ripley'), . - r ~ r)
jpenv = envelope(jp, Lest, nsim = 500, correction = 'Ripley', confidence = 0.95)
plot(envelope(jp, Lest, nsim = 500, correction = 'Ripley', confidence = 0.95), . - r ~ r)
plot(envelope(jp, Lest, nsim = 500, correction = 'Ripley', confidence = 0.8), . - r ~ r)
plot(envelope(jp, Lest, nsim = 500, correction = 'Ripley', confidence = 0.1), . - r ~ r)
plot(envelope(jp, Lest, nsim = 999, correction = 'Ripley', nrank = 2.5), . - r ~ r)
plot(envelope(jp, Lest, nsim = 999, correction = 'Ripley', nrank = 3), . - r ~ r)
plot(envelope(jp, Lest, nsim = 999, correction = 'Ripley', nrank = 20), . - r ~ r)
plot(envelope(jp, Lest, nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r)
plot(envelope(jp, Lest, nsim = 999, correction = 'Ripley', nrank = 100), . - r ~ r)
plot(envelope(jp, Lest, nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r)
plot(envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r)
plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp)
points(jp, pch = '.')
plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = '.')
plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
plot(jp)
r <- seq(0, 2000, len = 201)
Tobs <- max(Lest(jp, r = r,
correction = "Ripley")$iso - r)
Tobs <- max(Lest(jp, r = r, correction = "Ripley")$iso - r)
Tobs <- max(Lest(jp, correction = "Ripley")$iso - r)
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
max(Lest(jp[,sample.int(n, size = naf)],
correction = "Ripley")$iso - r)
})
plot(envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r)
plot(jp)
plot(jp, main = NULL)
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
plot(envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r)
plot(envelope(jp, fun = 'Lest', nsim = 100, correction = 'Ripley', nrank = 25), . - r ~ r, legend.shrink = 0.5)
plot(envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r, legend = FALSE)
warnings()
library(spatstat)
data(japanesepines, package = 'spatstat.data')
jp = japanesepines
plot(jp, main = NULL)
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
plot(envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25), . - r ~ r, legend = FALSE)
jpenv = envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25)
plot(jpenv, . - r ~ r, legend = FALSE, main = FALSE)
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL)
max(Lest(jp,
correction = "Ripley")$iso - r)
Tobs <- max(Lest(jp, correction = "Ripley")$iso - r)
r <- seq(0, 2000, len = 201)
Tobs <- max(Lest(jp, correction = "Ripley")$iso - r)
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
max(Lest(jp, correction = "Ripley")$iso - r)
})
mean(c(Tsim, Tobs) >= Tobs)
?Lest
Tobs <- max(Lest(jp, correction = "Ripley")$iso)
max(Lest(jp, correction = "Ripley")$iso)
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
max(Lest(jp, correction = "Ripley")$iso)
})
mean(c(Tsim, Tobs) >= Tobs)
r <- seq(0, 2000, len = 201)
Tobs <- max(Lest(jp, r = r, correction = "Ripley")$iso)
Tobs <- max(Lest(jp, r = r, correction = "Ripley")$iso - r)
R <- seq(0, 2000, len = 201)
Tobs <- max(Lest(jp, r = R, correction = "Ripley")$iso - R)
points(jp, pch = 20)}
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
jpenv = envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25)
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL)
jpenv = envelope(jp, fun = 'Lest', nsim = 999, correction = 'Ripley', nrank = 25)
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL)
Tobs = 4
# Under H0, say the distribution of the data is N(0, 1)
# Simulate data sets under H0
simdata = matrix(rnorm(10 * 999, mean = 0, sd = 1), nrow = 999, ncol = 10)
# calculate test statistic for each simulated data set
Tsim = rowMeans(simdata)/(apply(simdata, 1, sd)/sqrt(10))
# include observed test statistic to simulated test statistics
Tsim = c(Tsim, Tobs)
# determine proportion of test statistics as extreme as the observed
# test statistc
mean(Tsim >= Tobs)
n = 999
p = 0.05
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
plot(jpenv, . - r ~ r, legend = TRUE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = paste(expression(hat('L')), '(h) - h'), xlab = 'Distance (h)')
?expression
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L'), '(h)'), xlab = 'Distance (h)')
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L'), '(h)'), xlab = 'Distance (h)')
par(OP)
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
library(spatstat)
data(japanesepines, package = 'spatstat.data')
jp = japanesepines
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
library(spatstat)
data(japanesepines, package = 'spatstat.data')
jp = japanesepines
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
# x is a ppp
# nsim is the number of simulation from which to construct
# the tolerance envelopes
# level is the tolerance level of the envelopes
# ... is additional arguments passed to Lest
lplot <- function(x, nsim = 500, level = 0.95,
correction = "Ripley", ...) {
lobs <- spatstat::Lest(x, correction = correction, ...)
# lambda <- summary(x)$intensity
win <- x$window
lsim <- pbapply::pblapply(1:nsim, FUN = function(i) {
# xsim <- spatstat::rpoispp(lambda, win = win)
# generate n event locations over study area under CSR
xsim <- spatstat::runifpoint(n = x$n, win = win)
# estimate L for simulated point pattern
spatstat::Lest(xsim, correction = correction, ...)
})
r <- lobs$r # get distances
obs <- lobs$iso # get estimated l for observed
# get estimated l for each simulated data set
sim <- sapply(lsim, getElement, "iso")
# apply the min function to each row  (MARGIN = 1) of sim
# gets pointwise minimum for simulated data
# at each distance.  do same for max, quantiles, median
lo <- apply(sim, MARGIN = 1, FUN = min, na.rm = TRUE)
hi <- apply(sim, MARGIN = 1, FUN = max, na.rm = TRUE)
alpha <- 1 - level
qlo <- apply(sim, MARGIN = 1, FUN = quantile,
prob = alpha/2, na.rm = TRUE)
qhi <- apply(sim, MARGIN = 1, FUN = quantile,
prob = 1 - alpha/2, na.rm = TRUE)
med <- apply(sim, MARGIN = 1, FUN = median, na.rm = TRUE)
# construct empty plot of the right size
plot(range(r), c(min(c(lo, obs) - r, na.rm = TRUE),
max(c(hi, obs) - r, na.rm = TRUE)),
type = "n",
xlab = "distance", ylab = "L(distance) - distance")
# plot different statistics with differnt styles/thickness
lines(r, obs - r, lwd = 2)
lines(r, lo - r, lty = 2)
lines(r, hi - r, lty = 2)
lines(r, qlo - r, lty = 1)
lines(r, qhi - r, lty = 1)
}
lplot(jp)
lplot(jp)
library(spatstat)
data(japanesepines, package = 'spatstat.data')
jp = japanesepines
# x is a ppp
# nsim is the number of simulation from which to construct
# the tolerance envelopes
# level is the tolerance level of the envelopes
# ... is additional arguments passed to Lest
lplot <- function(x, nsim = 500, level = 0.95,
correction = "Ripley", ...) {
lobs <- spatstat::Lest(x, correction = correction, ...)
# lambda <- summary(x)$intensity
win <- x$window
lsim <- pbapply::pblapply(1:nsim, FUN = function(i) {
# xsim <- spatstat::rpoispp(lambda, win = win)
# generate n event locations over study area under CSR
xsim <- spatstat::runifpoint(n = x$n, win = win)
# estimate L for simulated point pattern
spatstat::Lest(xsim, correction = correction, ...)
})
r <- lobs$r # get distances
obs <- lobs$iso # get estimated l for observed
# get estimated l for each simulated data set
sim <- sapply(lsim, getElement, "iso")
# apply the min function to each row  (MARGIN = 1) of sim
# gets pointwise minimum for simulated data
# at each distance.  do same for max, quantiles, median
lo <- apply(sim, MARGIN = 1, FUN = min, na.rm = TRUE)
hi <- apply(sim, MARGIN = 1, FUN = max, na.rm = TRUE)
alpha <- 1 - level
qlo <- apply(sim, MARGIN = 1, FUN = quantile,
prob = alpha/2, na.rm = TRUE)
qhi <- apply(sim, MARGIN = 1, FUN = quantile,
prob = 1 - alpha/2, na.rm = TRUE)
med <- apply(sim, MARGIN = 1, FUN = median, na.rm = TRUE)
# construct empty plot of the right size
plot(range(r), c(min(c(lo, obs) - r, na.rm = TRUE),
max(c(hi, obs) - r, na.rm = TRUE)),
type = "n",
xlab = "distance", ylab = "L(distance) - distance")
# plot different statistics with differnt styles/thickness
lines(r, obs - r, lwd = 2)
lines(r, lo - r, lty = 2)
lines(r, hi - r, lty = 2)
lines(r, qlo - r, lty = 1)
lines(r, qhi - r, lty = 1)
}
lplot(jp)
jp$window
plot(jp, main = NULL)
{plot(density(jp, sigma = bw.scott(jp)), main = NULL)
contour(density(jp, sigma = bw.scott(jp)), add = TRUE)
points(jp, pch = 20)}
n = 999
p = 0.05
OP = par(mar = c(5,5,4,4))
jpenv = envelope(jp, fun = 'Lest', nsim = n, correction = 'Ripley', nrank = (p * (n + 1)))
plot(jpenv, . - r ~ r, legend = FALSE, main = NULL, ylab = expression(hat('L')), xlab = 'Distance (h)')
par(OP)
lplot(jp)
?csr
genome_tests_afr <- read.csv("~/GitHub/mixturesresearch/AncestryEstimation-App/genome_test_afr.txt", sep="")
genome_tests_amr <- read.csv("~/GitHub/mixturesresearch/AncestryEstimation-App/genome_test_amr.txt", sep="")
genome_tests_oth <- read.csv("~/GitHub/mixturesresearch/AncestryEstimation-App/genome_test_oth.txt", sep="")
exome_tests_afr <- read.csv("~/GitHub/mixturesresearch/AncestryEstimation-App/exome_test_afr.txt", sep="")
exome_tests_amr <- read.csv("~/GitHub/mixturesresearch/AncestryEstimation-App/exome_test_amr.txt", sep="")
exome_tests_oth <- read.csv("~/GitHub/mixturesresearch/AncestryEstimation-App/exome_test_oth.txt", sep="")
shiny::runApp('GitHub/mixturesresearch/AncestryEstimation-App')
shiny::runApp('GitHub/mixturesresearch/AncestryEstimation-App')
shiny::runApp('GitHub/mixturesresearch/AncestryEstimation-App')
